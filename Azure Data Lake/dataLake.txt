Target: Learn how to access Data Lake Storage
    + Create ADLS
    + Access DL using Access Keys
    + Access DL using SAS Token
    + Access DL using Service Principal
    + Using Cluster Scoped Authentication
    + Access DL using AAD Credential Pass-through
    + Recommened approach for the course

------------------------------------------------------------------------------------------------------------------------

- In order to access the Azure Data Lake Storage (ADLS)
    + Storage Access Keys (Each account)
    + Shared Access Signature (SAS Token) (can custom)
    + Service Principal: Create this to manage access to the ADLS

- There are two types of Scoped Authentication:
    + Session Scoped Authentication: Use the credentials in the notebook and authenticate to the Data Lake, authenticate until the notebook is detached from the cluster
    + Cluster Scoped Authentication: Use the credentials in the notebook and authenticate from the cluster, authenticate the cluster is terminated

- There are other kinds of authentication: (Learn Later)
    + AAD Passthrough Authentication
    + Unity Catalog

------------------------------------------------------------------------------------------------------------------------

- Authenticate using Access Keys:
    + Each storage account comes with 2 keys (Why???)
    + Gives full Access to the storage account
    + Keys can be rotated (regenerated)

- Assign a key access to the Azure Databricks through Spark Configuration

------------------------------------------------------------------------------------------------------------------------

- Authenticate ussing SAS Token:
    + Provides fine grained access to the storage
    + Restrict access to specific resource types / services
    + Allow specific permissions
    + Restrict access to specific time period
    + Limit access to specific IP addresses
    + Recommended access pattern for external clients

------------------------------------------------------------------------------------------------------------------------

- Authenticate using Service Principal: Similar to the user account
    + Register Azure AD Application / Service Principal -> Unique ID (Application/ClientID)
    + Generate a secret / password for the Application
    + Set Spark Config with App / Client Id, Directory / Tenant Id & Secret
    + Assign Role Storage Blob Data Contributor to the Data Lake

------------------------------------------------------------------------------------------------------------------------

- AAD Passthrough Authentication:
    + Assign permissions for each user